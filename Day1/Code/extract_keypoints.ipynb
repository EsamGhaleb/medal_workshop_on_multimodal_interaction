{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3679256",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m \u001b[38;5;66;03m# Python package for system-specific parameters and functions\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtest_segmentation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_args, set_random_seed, train_with_config, get_config \n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextract_mp_pose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extract_keypoints \u001b[38;5;66;03m# Extract keypoints from images using MediaPipe Pose (sim)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/test_segmentation.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01margparse\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merrno\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import sys # Python package for system-specific parameters and functions\n",
    "from test_segmentation import parse_args, set_random_seed, train_with_config, get_config \n",
    "from utils.extract_mp_pose import extract_keypoints # Extract keypoints from images using MediaPipe Pose (sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c5494",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef535f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "I0000 00:00:1749840711.937480 16526762 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M3 Pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video resolution: 1280.0x720.0, FPS: 25.0\n",
      "Number of frames in the video: 22056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames:   0%|          | 0/22056 [00:00<?, ?frame/s]W0000 00:00:1749840712.009590 16529573 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749840712.020109 16529575 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749840712.021219 16529581 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749840712.021276 16529575 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749840712.021287 16529573 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749840712.024889 16529573 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749840712.026759 16529583 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1749840712.026791 16529577 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Processing frames:   5%|▌         | 1200/22056 [00:55<16:10, 21.49frame/s]\n"
     ]
    }
   ],
   "source": [
    "return_dict = extract_keypoints(vidf=\"test_videos/tedtalk.webm\", save_video=True) # Change this to the desired video file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_videos/tedtalk.npy'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_dict['output_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b36e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing with poses in test_videos/tedtalk.npy ===\n",
      "{'train_2d': True, 'has_3d': False, 'no_eval': True, 'finetune': False, 'partial_train': None, 'phase': 'test', 'apply_skeleton_augmentations': True, 'epochs': 200, 'checkpoint_frequency': 30, 'batch_size': 96, 'dropout': 0.1, 'learning_rate': 0.0003, 'weight_decay': 0.01, 'lr_decay': 0.99, 'pretrain_3d_curriculum': 30, 'maxlen': 120, 'dim_feat': 128, 'mlp_ratio': 2, 'depth': 4, 'dim_rep': 256, 'hidden_dim': 256, 'num_heads': 8, 'att_fuse': True, 'pretrained': '', 'model_args': {'modalities': ['skeleton'], 'fusion': 'unimodal', 'feat_dim': 128, 'w2v2_type': 'multilingual', 'skeleton_backbone': 'jointsformer', 'hidden_dim': 256, 'attentive_pooling': True, 'attentive_pooling_skeleton': True, 'bertje_dim': 768, 'freeze_bertje': True, 'cross_modal': False, 'one_branch_cross_modal': False, 'multimodal_embeddings_dim': 1024, 'apply_cnn': False, 'maxlen': 120}, 'modalities': ['skeleton'], 'loss_type': ['cross_entropy'], 'use_contrastive': True, 'temp': 0.1, 'freeze_bertje': True, 'bertje_dim': 768, 'name': 'CABB_segment_basic_test'}\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing segmentation sequences...: 100%|██████████| 1/1 [00:00<00:00, 15827.56it/s]\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/opt/anaconda3/envs/whisperx/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "Restoring states from the checkpoint path at CABB_Segmentation/fold_1/checkpoints/fold_1/last.ckpt\n",
      "/opt/anaconda3/envs/whisperx/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/data/clusterfs/mld/users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_1/checkpoints/CABB-segmentation-20250530_195652_fold_1' to '/Users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_1/checkpoints/CABB-segmentation-20250613_205247_fold_1', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "Loaded model weights from the checkpoint at CABB_Segmentation/fold_1/checkpoints/fold_1/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 3 4 5 6 7 9] [2 8]\n",
      "Starting Fold 1\n",
      "INFO: Trainable parameter count: 3345161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/whisperx/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/whisperx/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 10. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/segmentation_loss   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05076472833752632    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/segmentation_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05076472833752632   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at CABB_Segmentation/fold_2/checkpoints/fold_2/last.ckpt\n",
      "/opt/anaconda3/envs/whisperx/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/data/clusterfs/mld/users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_2/checkpoints/CABB-segmentation-20250530_195652_fold_2' to '/Users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_2/checkpoints/CABB-segmentation-20250613_205247_fold_2', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "Loaded model weights from the checkpoint at CABB_Segmentation/fold_2/checkpoints/fold_2/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 5 6 7 8] [4 9]\n",
      "Starting Fold 2\n",
      "INFO: Trainable parameter count: 3345161\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/segmentation_loss   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.041764672845602036    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/segmentation_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.041764672845602036   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at CABB_Segmentation/fold_3/checkpoints/fold_3/last.ckpt\n",
      "/opt/anaconda3/envs/whisperx/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/data/clusterfs/mld/users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_3/checkpoints/CABB-segmentation-20250530_195652_fold_3' to '/Users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_3/checkpoints/CABB-segmentation-20250613_205247_fold_3', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "Loaded model weights from the checkpoint at CABB_Segmentation/fold_3/checkpoints/fold_3/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 3 4 5 7 8 9] [1 6]\n",
      "Starting Fold 3\n",
      "INFO: Trainable parameter count: 3345161\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/segmentation_loss   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.04847728833556175    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/segmentation_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.04847728833556175   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at CABB_Segmentation/fold_4/checkpoints/fold_4/last.ckpt\n",
      "/opt/anaconda3/envs/whisperx/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/data/clusterfs/mld/users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_4/checkpoints/CABB-segmentation-20250530_195652_fold_4' to '/Users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_4/checkpoints/CABB-segmentation-20250613_205247_fold_4', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "Loaded model weights from the checkpoint at CABB_Segmentation/fold_4/checkpoints/fold_4/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 4 5 6 8 9] [3 7]\n",
      "Starting Fold 4\n",
      "INFO: Trainable parameter count: 3345161\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/segmentation_loss   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.044202398508787155    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/segmentation_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.044202398508787155   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at CABB_Segmentation/fold_5/checkpoints/fold_5/last.ckpt\n",
      "/opt/anaconda3/envs/whisperx/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:362: The dirpath has changed from '/data/clusterfs/mld/users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_5/checkpoints/CABB-segmentation-20250530_195652_fold_5' to '/Users/esagha/Projects/medal_workshop_on_multimodal_interaction/Gesture_Segmentation_Toturial/Code/CABB_Segmentation/fold_5/checkpoints/CABB-segmentation-20250613_205247_fold_5', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "Loaded model weights from the checkpoint at CABB_Segmentation/fold_5/checkpoints/fold_5/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 6 7 8 9] [0 5]\n",
      "Starting Fold 5\n",
      "INFO: Trainable parameter count: 3345161\n",
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/segmentation_loss   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.03944703936576843    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m test/segmentation_loss  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.03944703936576843   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to CABB_Segmentation/fold_5/test_results.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# pretend the notebook “argv” is your list\n",
    "sys.argv = [\"run_segmentation_test.py\"] + [\n",
    "    \"--config\",  \"config/segmentation/CABB_segment_basic_test.yaml\",  # add if you need it\n",
    "    \"--poses-path\", return_dict['output_path'],\n",
    "    \"--phase\",  \"test\",\n",
    "    \"--seed\",   \"42\",\n",
    "    \"--devices\", \"0\"\n",
    "]\n",
    "\n",
    "opts = parse_args()          # now reads from our fake sys.argv\n",
    "set_random_seed(opts.seed)\n",
    "args = get_config(opts.config)\n",
    "\n",
    "print(f\"=== Testing with poses in {opts.poses_path} ===\")\n",
    "segmentation_results = train_with_config(args, opts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=return_dict['output_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 207.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 - Number of samples: 10, Number of sequences: 120\n",
      "Fold 1 - Number of samples: 10, Number of sequences: 120\n",
      "Fold 2 - Number of samples: 10, Number of sequences: 120\n",
      "Fold 3 - Number of samples: 10, Number of sequences: 120\n",
      "Fold 4 - Number of samples: 10, Number of sequences: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 147.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair: 77\n",
      "Speaker: B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from Gesture_Segmentation_to_ELAN import get_elan_files\n",
    "# copy segmentation_results \n",
    "segmentation_results_copy = segmentation_results.copy()\n",
    "get_elan_files(segmentation_results_copy, fps=return_dict['samplerate'], model='skeleton', threshold=0.55, file_path=return_dict['output_path'], video_output_path=return_dict['video_output_path'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
